# -*- coding: utf-8 -*-
"""Hackscript.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1UAq7uZOgMndJINHRTRJHJNCWoQi7QeS4
"""

import os
import zipfile

# Define the paths to the uploaded zip files
document_zip_path = '/content/document_dataset.zip'
signature_zip_path = '/content/signature_dataset1.zip'

# Define the extraction paths
document_extraction_path = '/content/document_dataset'
signature_extraction_path = '/content/signature_dataset1'

# Extract the document dataset
with zipfile.ZipFile(document_zip_path, 'r') as zip_ref:
    zip_ref.extractall(document_extraction_path)

# Extract the signature dataset
with zipfile.ZipFile(signature_zip_path, 'r') as zip_ref:
    zip_ref.extractall(signature_extraction_path)

# Verify the extraction and directory structure
print("Document dataset structure:")
for root, dirs, files in os.walk(document_extraction_path):
    level = root.replace(document_extraction_path, '').count(os.sep)
    indent = ' ' * 4 * (level)
    print(f"{indent}{os.path.basename(root)}/")
    subindent = ' ' * 4 * (level + 1)
    for f in files:
        print(f"{subindent}{f}")

print("\nSignature dataset structure:")
for root, dirs, files in os.walk(signature_extraction_path):
    level = root.replace(signature_extraction_path, '').count(os.sep)
    indent = ' ' * 4 * (level)
    print(f"{indent}{os.path.basename(root)}/")
    subindent = ' ' * 4 * (level + 1)
    for f in files:
        print(f"{subindent}{f}")

import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Define paths
document_dir = '/content/document_dataset'
signature_dir = '/content/signature_dataset1'

# Data augmentation and preprocessing for documents
document_datagen = ImageDataGenerator(
    rescale=1.0/255.0,
    validation_split=0.25,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True
)

# Data augmentation and preprocessing for signatures
signature_datagen = ImageDataGenerator(
    rescale=1.0/255.0,
    validation_split=0.25,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True
)

# Load training and validation sets for documents
document_train_generator = document_datagen.flow_from_directory(
    document_dir,
    target_size=(150, 150),
    batch_size=32,
    class_mode='binary',
    subset='training'
)

document_validation_generator = document_datagen.flow_from_directory(
    document_dir,
    target_size=(150, 150),
    batch_size=32,
    class_mode='binary',
    subset='validation'
)

# Load training and validation sets for signatures
signature_train_generator = signature_datagen.flow_from_directory(
    signature_dir,
    target_size=(150, 150),
    batch_size=32,
    class_mode='binary',
    subset='training'
)

signature_validation_generator = signature_datagen.flow_from_directory(
    signature_dir,
    target_size=(150, 150),
    batch_size=32,
    class_mode='binary',
    subset='validation'
)

# Check if generators found data
print("Document training data:", len(document_train_generator.filenames))
print("Document validation data:", len(document_validation_generator.filenames))
print("Signature training data:", len(signature_train_generator.filenames))
print("Signature validation data:", len(signature_validation_generator.filenames))

# Define a CNN model
model = tf.keras.models.Sequential([
    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),
    tf.keras.layers.MaxPooling2D(2, 2),
    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2, 2),
    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2, 2),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(512, activation='relu'),
    tf.keras.layers.Dense(1, activation='sigmoid')
])

# Compile the model
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Train the model on document dataset
document_history = model.fit(
    document_train_generator,
    epochs=10,
    validation_data=document_validation_generator
)

# Train the model on signature dataset
signature_history = model.fit(
    signature_train_generator,
    epochs=10,
    validation_data=signature_validation_generator
)

# Evaluate the model on document dataset
document_loss, document_accuracy = model.evaluate(document_validation_generator)
print(f"Document Validation Accuracy: {document_accuracy * 100:.2f}%")

# Evaluate the model on signature dataset
signature_loss, signature_accuracy = model.evaluate(signature_validation_generator)
print(f"Signature Validation Accuracy: {signature_accuracy * 100:.2f}%")

from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Data augmentation and preprocessing for documents
document_datagen = ImageDataGenerator(
    rescale=1.0/255.0,
    validation_split=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    rotation_range=40,
    width_shift_range=0.2,
    height_shift_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)

# Data augmentation and preprocessing for signatures
signature_datagen = ImageDataGenerator(
    rescale=1.0/255.0,
    validation_split=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    rotation_range=40,
    width_shift_range=0.2,
    height_shift_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)

from tensorflow.keras.applications import VGG16
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Flatten, Dense, Dropout

# Load the VGG16 model pre-trained on ImageNet, excluding the top layers
base_model = VGG16(weights='imagenet', include_top=False, input_shape=(150, 150, 3))

# Add custom top layers
x = base_model.output
x = Flatten()(x)
x = Dense(512, activation='relu')(x)
x = Dropout(0.5)(x)
predictions = Dense(1, activation='sigmoid')(x)

# Combine base model and custom layers into a new model
model = Model(inputs=base_model.input, outputs=predictions)

# Freeze the layers of the base model
for layer in base_model.layers:
    layer.trainable = False

# Compile the model
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Train the model on document dataset
document_history = model.fit(
    document_train_generator,
    epochs=10,
    validation_data=document_validation_generator
)

# Unfreeze the top layers of the base model for fine-tuning
for layer in base_model.layers[-4:]:
    layer.trainable = True

# Re-compile the model with a lower learning rate
model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5), loss='binary_crossentropy', metrics=['accuracy'])

# Continue training the model on document dataset
document_history_fine_tune = model.fit(
    document_train_generator,
    epochs=10,
    validation_data=document_validation_generator
)

from tensorflow.keras.layers import BatchNormalization

# Add custom top layers with regularization
x = base_model.output
x = Flatten()(x)
x = Dense(512, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001))(x)
x = BatchNormalization()(x)
x = Dropout(0.5)(x)
predictions = Dense(1, activation='sigmoid')(x)

# Combine base model and custom layers into a new model
model = Model(inputs=base_model.input, outputs=predictions)

# Compile and train the model as shown above

from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint

# Define callbacks
early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)
model_checkpoint = ModelCheckpoint('best_model.h5', save_best_only=True, monitor='val_loss')

# Assuming 'model' is defined in the previous cell (cell 24)
# Compile the model
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy']) # Added this line to compile the model

# Train the model with callbacks
document_history = model.fit(
    document_train_generator,
    epochs=50,
    validation_data=document_validation_generator,
    callbacks=[early_stopping, model_checkpoint]
)

# Evaluate the model on document dataset
document_loss, document_accuracy = model.evaluate(document_validation_generator)
print(f"Document Validation Accuracy: {document_accuracy * 100:.2f}%")

# Evaluate the model on signature dataset
signature_loss, signature_accuracy = model.evaluate(signature_validation_generator)
print(f"Signature Validation Accuracy: {signature_accuracy * 100:.2f}%")

import os
import zipfile
import numpy as np
from tensorflow.keras.preprocessing.image import img_to_array, load_img
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Lambda
from tensorflow.keras.optimizers import Adam
from tensorflow.keras import backend as K
from sklearn.model_selection import train_test_split

# Extract the dataset
def extract_dataset(zip_path, extract_to):
    with zipfile.ZipFile(zip_path, 'r') as zip_ref:
        zip_ref.extractall(extract_to)

# Paths
document_zip_path = '/content/document_dataset.zip'
signature_zip_path = '/content/signature_dataset.zip'
document_extraction_path = '/content/document_dataset'
signature_extraction_path = '/content/signature_dataset'

# Extract datasets
extract_dataset(document_zip_path, document_extraction_path)
extract_dataset(signature_zip_path, signature_extraction_path)

# Load images and create pairs
def load_images_and_labels(base_path):
    categories = os.listdir(base_path)
    label_dict = {category: idx for idx, category in enumerate(categories)}
    images = []
    labels = []
    for category in categories:
        category_path = os.path.join(base_path, category)
        for img_name in os.listdir(category_path):
            img_path = os.path.join(category_path, img_name)
            if os.path.isfile(img_path):  # Ensure it's a file, not a directory
                img = load_img(img_path, target_size=(150, 150))
                img = img_to_array(img)
                images.append(img)
                labels.append(label_dict[category])
    return np.array(images), np.array(labels)

# Create pairs
def create_pairs(images, labels):
    pairs = []
    labels_pairs = []
    num_classes = len(np.unique(labels))
    digit_indices = [np.where(labels == i)[0] for i in range(num_classes)]

    for idx1 in range(len(images)):
        # Create a positive pair
        x1, y1 = images[idx1], labels[idx1]
        idx2 = np.random.choice(digit_indices[y1])
        x2 = images[idx2]
        pairs += [[x1, x2]]
        labels_pairs += [1]

        # Create a negative pair
        idx2 = np.random.choice(digit_indices[(y1 + np.random.randint(1, num_classes)) % num_classes])
        x2 = images[idx2]
        pairs += [[x1, x2]]
        labels_pairs += [0]

    return np.array(pairs), np.array(labels_pairs)

# Load images and labels
images, labels = load_images_and_labels(signature_extraction_path)

# Create pairs
pairs, labels_pairs = create_pairs(images, labels)

# Split into training and validation sets
pairs_train, pairs_val, labels_train, labels_val = train_test_split(pairs, labels_pairs, test_size=0.2, random_state=42)

# Define the Siamese network
def build_siamese_model(input_shape):
    input = Input(input_shape)
    x = Conv2D(64, (10, 10), activation='relu')(input)
    x = MaxPooling2D((2, 2))(x)
    x = Conv2D(128, (7, 7), activation='relu')(x)
    x = MaxPooling2D((2, 2))(x)
    x = Conv2D(128, (4, 4), activation='relu')(x)
    x = MaxPooling2D((2, 2))(x)
    x = Conv2D(256, (4, 4), activation='relu')(x)
    x = Flatten()(x)
    x = Dense(4096, activation='sigmoid')(x)
    model = Model(input, x)
    return model

# Define the distance function
def euclidean_distance(vectors):
    (featsA, featsB) = vectors
    sum_squared = K.sum(K.square(featsA - featsB), axis=1, keepdims=True)
    return K.sqrt(K.maximum(sum_squared, K.epsilon()))

# Define the contrastive loss function
def contrastive_loss(y, preds, margin=1):
    y = K.cast(y, preds.dtype)
    squared_preds = K.square(preds)
    squared_margin = K.square(K.maximum(margin - preds, 0))
    loss = K.mean(y * squared_preds + (1 - y) * squared_margin)
    return loss

# Input shape
input_shape = (150, 150, 3)

# Build the base network
base_network = build_siamese_model(input_shape)

# Create the inputs
imgA = Input(shape=input_shape)
imgB = Input(shape=input_shape)

# Generate the feature vectors
featsA = base_network(imgA)
featsB = base_network(imgB)

# Compute the euclidean distance between the vectors
distance = Lambda(euclidean_distance)([featsA, featsB])

# Build the model
model = Model(inputs=[imgA, imgB], outputs=distance)

# Compile the model
model.compile(loss=contrastive_loss, optimizer=Adam(learning_rate=0.001))

# Train the model
history = model.fit(
    [pairs_train[:, 0], pairs_train[:, 1]], labels_train,
    validation_data=([pairs_val[:, 0], pairs_val[:, 1]], labels_val),
    batch_size=32,
    epochs=20
)

# Evaluate the model
results = model.evaluate([pairs_val[:, 0], pairs_val[:, 1]], labels_val)
print(f"Validation Loss: {results}")

# Save the model
model.save('siamese_signature_detection_model.h5')

import numpy as np
from tensorflow.keras.models import load_model
from sklearn.metrics import accuracy_score
from tensorflow.keras import backend as K  # Import backend
from tensorflow.keras.utils import custom_object_scope  # Import custom_object_scope


# Define the distance function (This needs to be defined before loading the model)
def euclidean_distance(vectors):
    (featsA, featsB) = vectors
    sum_squared = K.sum(K.square(featsA - featsB), axis=1, keepdims=True)
    return K.sqrt(K.maximum(sum_squared, K.epsilon()))


# Define a function to compute accuracy
def compute_accuracy(y_true, y_pred, threshold=0.5):
    y_pred = np.array(y_pred)
    y_pred_labels = (y_pred < threshold).astype(int)
    return accuracy_score(y_true, y_pred_labels)


# Load the trained model using custom_object_scope
with custom_object_scope({'euclidean_distance': euclidean_distance, 'contrastive_loss': contrastive_loss}):  # Add contrastive_loss if used
    model = load_model('siamese_signature_detection_model.h5', compile=False)


# Evaluate the model on the validation set
distances = model.predict([pairs_val[:, 0], pairs_val[:, 1]])
accuracy = compute_accuracy(labels_val, distances)

print(f"Validation Accuracy: {accuracy * 100:.2f}%")

